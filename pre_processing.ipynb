{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcddb431",
   "metadata": {},
   "source": [
    "# IOP PDFF Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea88135c",
   "metadata": {},
   "source": [
    "### Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from scipy.ndimage import zoom\n",
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "import nibabel as nib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82abfa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_directory = \"D:\\GEA21\\water\\A21_01\\WATER_IDEAL_IQ_PDFF_1101\\IM-0066-0001.dcm\"\n",
    "in_directory = \"D:\\GEA21\\in_out\\A21_01\\InPhase_LAVA_FLEX_adb_+_pelvis_1001/IM-0063-0001.dcm\"\n",
    "out_directory = \"D:\\GEA21\\in_out\\A21_01\\OutPhase_LAVA_FLEX_adb_+_pelvis_1002/IM-0064-0001.dcm\"\n",
    "\n",
    "water_img = pydicom.dcmread(water_directory)\n",
    "in_img = pydicom.dcmread(in_directory)\n",
    "out_img = pydicom.dcmread(out_directory)\n",
    "\n",
    "water_x_y = water_img.PixelSpacing\n",
    "water_slice_thickness = getattr(water_img, 'SliceThickness', None)\n",
    "water_spacing_between_slices = getattr(water_img, 'SpacingBetweenSlices', None)\n",
    "\n",
    "\n",
    "in_x_y = in_img.PixelSpacing\n",
    "in_slice_thickness = getattr(in_img, 'SliceThickness', None)\n",
    "in_spacing_between_slices = getattr(in_img, 'SpacingBetweenSlices', None)\n",
    "\n",
    "out_x_y = out_img.PixelSpacing\n",
    "out_slice_thickness = getattr(out_img, 'SliceThickness', None)\n",
    "out_spacing_between_slices = getattr(out_img, 'SpacingBetweenSlices', None)\n",
    "\n",
    "print(\"X Y Pixel Spacing\")\n",
    "print(water_x_y)\n",
    "print(in_x_y)\n",
    "print(out_x_y)\n",
    "\n",
    "print(\"Slice Thickness\")\n",
    "print(water_slice_thickness)\n",
    "print(in_slice_thickness)\n",
    "print(out_slice_thickness)\n",
    "\n",
    "print(\"Slice Spacing\")\n",
    "print(water_spacing_between_slices)\n",
    "print(in_spacing_between_slices)\n",
    "print(out_spacing_between_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d2113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_volume(volume, original_spacing, target_spacing, order=1):\n",
    "    zoom_factors = [original_spacing[i] / target_spacing[i] for i in range(3)]\n",
    "    return zoom(volume, zoom=zoom_factors, order=order)\n",
    "\n",
    "def load_dicom_volume(folder_path):\n",
    "    slices = []\n",
    "    \n",
    "    # Load all .dcm files and sort by ImagePositionPatient (Z coordinate)\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".dcm\"):\n",
    "            dcm = pydicom.dcmread(os.path.join(folder_path, filename))\n",
    "            slices.append(dcm)\n",
    "\n",
    "    # Sort by the z-axis (ImagePositionPatient[2])\n",
    "    slices.sort(key=lambda dcm: float(dcm.ImagePositionPatient[2]))\n",
    "\n",
    "    # Build the 3D volume\n",
    "    volume = np.stack([s.pixel_array for s in slices])\n",
    "\n",
    "    # Get spacing info\n",
    "    pixel_spacing = slices[0].PixelSpacing      # [row, col] = [Y, X]\n",
    "    slice_spacing = float(slices[1].ImagePositionPatient[2] - slices[0].ImagePositionPatient[2])  # Z\n",
    "\n",
    "    spacing = [slice_spacing, pixel_spacing[0], pixel_spacing[1]]  # [Z, Y, X]\n",
    "\n",
    "    return volume, spacing\n",
    "\n",
    "def pad_z(image, target_slices):\n",
    "    current_slices = image.shape[0]\n",
    "    \n",
    "    if target_slices < current_slices:\n",
    "        raise ValueError(\"target_slices must be greater than or equal to the current number of slices.\")\n",
    "    \n",
    "    total_pad = target_slices - current_slices\n",
    "    pad_before = total_pad // 2\n",
    "    pad_after = total_pad - pad_before\n",
    "    \n",
    "    padding = ((pad_before, pad_after), (0, 0), (0, 0))\n",
    "    \n",
    "    padded_image = np.pad(image, padding, mode='constant', constant_values=0)\n",
    "    \n",
    "    return padded_image\n",
    "\n",
    "def normalize(image):\n",
    "    min_val, max_val = np.min(image), np.max(image)\n",
    "    if max_val == min_val:\n",
    "        return np.zeros_like(image, dtype=np.float32)\n",
    "    return (image - min_val) / (max_val - min_val)\n",
    "\n",
    "def get_consistent_spacing(seg_spacing, ref_spacing, tol=0.25):\n",
    "    \"\"\"\n",
    "    Detects large spacing mismatches. If segmentation spacing differs\n",
    "    too much from MRI spacing, returns MRI spacing instead.\n",
    "    \"\"\"\n",
    "    z_ratio = seg_spacing[0] / ref_spacing[0]\n",
    "    if abs(z_ratio - 1) > tol:\n",
    "        print(f\"‚ö†Ô∏è  Large Z spacing mismatch ({seg_spacing[0]:.3f} vs {ref_spacing[0]:.3f}) ‚Üí using MRI spacing.\")\n",
    "        return ref_spacing\n",
    "    return seg_spacing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def crop_outphase_to_liver(img_outphase, mask_outphase, pad_slices=25, min_slices=64):\n",
    "    img_z, mask_z = img_outphase.shape[0], mask_outphase.shape[0]\n",
    "    # --- Handle small Z mismatches ---\n",
    "    if img_z != mask_z:\n",
    "        diff = abs(img_z - mask_z)\n",
    "        if diff <= 3:\n",
    "            print(f\"Adjusting Z mismatch: image={img_z}, mask={mask_z}\")\n",
    "            min_z = min(img_z, mask_z)\n",
    "            img_outphase = img_outphase[:min_z, :, :]\n",
    "            mask_outphase = mask_outphase[:min_z, :, :]\n",
    "        else:\n",
    "            raise ValueError(f\"Z mismatch too large: image={img_z}, mask={mask_z}\")\n",
    "\n",
    "    # --- Identify liver region ---\n",
    "    z_indices = np.any(mask_outphase > 0, axis=(1, 2))\n",
    "    if not np.any(z_indices):\n",
    "        raise ValueError(\"No liver region found in mask_outphase!\")\n",
    "\n",
    "    z_min, z_max = np.where(z_indices)[0][[0, -1]]\n",
    "\n",
    "    # --- Add padding ---\n",
    "    z_start = max(z_min - pad_slices, 0)\n",
    "    z_end = min(z_max + pad_slices + 1, img_outphase.shape[0])\n",
    "    crop_size = z_end - z_start\n",
    "\n",
    "    # --- If cropped region < min_slices, expand symmetrically ---\n",
    "    if crop_size < min_slices:\n",
    "        deficit = min_slices - crop_size\n",
    "        half_extra = deficit // 2\n",
    "\n",
    "        # Try expanding equally on both sides\n",
    "        new_start = max(z_start - half_extra, 0)\n",
    "        new_end = min(z_end + (deficit - half_extra), img_outphase.shape[0])\n",
    "\n",
    "        # If expansion still too small (near edges), push to bounds\n",
    "        if new_end - new_start < min_slices:\n",
    "            # Try expanding only in the available direction\n",
    "            if new_start == 0:\n",
    "                new_end = min(min_slices, img_outphase.shape[0])\n",
    "            elif new_end == img_outphase.shape[0]:\n",
    "                new_start = max(0, img_outphase.shape[0] - min_slices)\n",
    "\n",
    "        z_start, z_end = new_start, new_end\n",
    "\n",
    "    # --- Crop ---\n",
    "    cropped_img = img_outphase[z_start:z_end, :, :]\n",
    "    cropped_mask = mask_outphase[z_start:z_end, :, :]\n",
    "\n",
    "    print(f\"Cropped from slice {z_start} to {z_end} ‚Üí {z_end - z_start} slices kept (min={min_slices}).\")\n",
    "    return cropped_img, cropped_mask, z_start, z_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5210b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(base_dir):\n",
    "    water_dir = os.path.join(base_dir, 'water/')\n",
    "    in_dir = os.path.join(base_dir, 'in_out/')\n",
    "    water_seg_dir = os.path.join(base_dir, 'water_segmentations/')\n",
    "    out_seg_dir = os.path.join(base_dir, 'out_segmentations/')\n",
    "\n",
    "    water_imgs = sorted(os.listdir(water_dir))\n",
    "    in_imgs = sorted(os.listdir(in_dir))\n",
    "    water_segs = sorted(os.listdir(water_seg_dir))\n",
    "    out_segs = sorted(os.listdir(out_seg_dir))\n",
    "\n",
    "    water_vols, inphase_vols, outphase_vols = [], [], []\n",
    "    water_masks, outphase_masks = [], []\n",
    "\n",
    "    skipped = []\n",
    "\n",
    "    for i in range(len(water_imgs)):\n",
    "        try:\n",
    "            # --- Load water ---\n",
    "            img_dir = glob.glob(os.path.join(water_dir, water_imgs[i], \"*\"))[0] + \"/\"\n",
    "            water_vol, water_spacing = load_dicom_volume(img_dir)\n",
    "            water_vols.append(normalize(water_vol))\n",
    "\n",
    "            # --- Load in/outphase ---\n",
    "            in_folder = glob.glob(os.path.join(in_dir, in_imgs[i], \"*\"))\n",
    "            inphase_folders = [f for f in in_folder if \"inphase\" in f.lower()]\n",
    "            outphase_folders = [f for f in in_folder if \"outphase\" in f.lower()]\n",
    "\n",
    "            in_vol, in_spacing = load_dicom_volume(inphase_folders[0] + '/')\n",
    "            out_vol, out_spacing = load_dicom_volume(outphase_folders[0] + '/')\n",
    "\n",
    "            in_res = resample_volume(in_vol, in_spacing, water_spacing)\n",
    "            out_res = resample_volume(out_vol, out_spacing, water_spacing)\n",
    "            inphase_vols.append(in_res)\n",
    "            outphase_vols.append(out_res)\n",
    "\n",
    "            # --- Load water segmentation ---\n",
    "            water_seg = nib.load(os.path.join(water_seg_dir, water_segs[i]))\n",
    "            seg_data = np.flip(water_seg.get_fdata(), axis=1)\n",
    "            seg_data = np.transpose(seg_data, (2, 1, 0))\n",
    "            affine = water_seg.affine\n",
    "            seg_spacing = np.abs(affine.diagonal())[:3][::-1]\n",
    "            water_res = resample_volume(seg_data, seg_spacing, water_spacing, order=0)\n",
    "            water_masks.append((water_res > 0).astype(np.uint8))\n",
    "\n",
    "            # --- Load outphase segmentation ---\n",
    "            out_seg = nib.load(os.path.join(out_seg_dir, out_segs[i]))\n",
    "            seg_data = np.flip(out_seg.get_fdata(), axis=1)\n",
    "            seg_data = np.transpose(seg_data, (2, 1, 0))\n",
    "            affine = out_seg.affine\n",
    "            seg_spacing = np.abs(affine.diagonal())[:3][::-1]\n",
    "            spacing_used = get_consistent_spacing(seg_spacing, out_spacing)\n",
    "            out_res_seg = resample_volume(seg_data, spacing_used, water_spacing, order=0)\n",
    "            out_mask = (out_res_seg > 0).astype(np.uint8)\n",
    "            outphase_masks.append(out_mask)\n",
    "\n",
    "            # --- Crop and normalize ---\n",
    "            cropped_out_img, cropped_out_mask, z_start, z_end = crop_outphase_to_liver(\n",
    "                out_resample := out_res,\n",
    "                out_mask,\n",
    "                pad_slices=25\n",
    "            )\n",
    "            cropped_in_img = in_res[z_start:z_end, :, :]\n",
    "\n",
    "            outphase_vols[-1] = normalize(cropped_out_img)\n",
    "            inphase_vols[-1] = normalize(cropped_in_img)\n",
    "            outphase_masks[-1] = cropped_out_mask\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Skipping subject {water_imgs[i]} due to error: {e}\")\n",
    "            skipped.append(water_imgs[i])\n",
    "\n",
    "            # Remove any partially added volumes to keep list alignment\n",
    "            for lst in [water_vols, inphase_vols, outphase_vols, water_masks, outphase_masks]:\n",
    "                if len(lst) > i - len(skipped):  # remove last entry if added\n",
    "                    lst.pop()\n",
    "\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n‚úÖ Finished {base_dir}\")\n",
    "    print(f\"   Processed: {len(water_vols)} subjects\")\n",
    "    print(f\"   Skipped:   {len(skipped)} subjects ‚Üí {skipped}\")\n",
    "\n",
    "    return water_vols, inphase_vols, outphase_vols, water_masks, outphase_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c6d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['D:/GEA21', 'D:/SBIR_PDFF', 'D:/SBIR_T1', 'D:/WLS02_UCSD']\n",
    "\n",
    "all_water_volumes, all_inphase_volumes, all_outphase_volumes = [], [], []\n",
    "all_water_segmentations, all_outphase_segmentations = [], []\n",
    "\n",
    "for dataset_path in datasets:\n",
    "    print(f\"\\n=== Processing {dataset_path} ===\")\n",
    "    (water_volumes, inphase_volumes, outphase_volumes,\n",
    "     water_segmentations, outphase_segmentations) = preprocess_dataset(dataset_path)\n",
    "\n",
    "    all_water_volumes.extend(water_volumes)\n",
    "    all_inphase_volumes.extend(inphase_volumes)\n",
    "    all_outphase_volumes.extend(outphase_volumes)\n",
    "    all_water_segmentations.extend(water_segmentations)\n",
    "    all_outphase_segmentations.extend(outphase_segmentations)\n",
    "\n",
    "print(f\"\\n‚úÖ Total subjects processed: {len(all_water_volumes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde49869",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_water_volumes))\n",
    "print(all_water_volumes[0].shape)\n",
    "print(all_inphase_volumes[0].shape)\n",
    "print(all_outphase_volumes[0].shape)\n",
    "print(all_water_segmentations[0].shape)\n",
    "print(all_outphase_segmentations[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5122aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(30, 40):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.subplot(151)\n",
    "#     plt.imshow(all_water_volumes[0][i,:,:], cmap='gray')\n",
    "#     plt.subplot(152)\n",
    "#     plt.imshow(all_inphase_volumes[0][i,:,:], cmap='gray')\n",
    "#     plt.subplot(153)\n",
    "#     plt.imshow(all_outphase_volumes[0][i,:,:], cmap='gray')\n",
    "#     plt.subplot(154)\n",
    "#     plt.imshow(all_water_segmentations[0][i,:,:], cmap='gray')\n",
    "#     plt.subplot(155)\n",
    "#     plt.imshow(all_outphase_segmentations[0][i,:,:], cmap='gray')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369fb836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max shape across ALL volumes\n",
    "all_vols = all_water_volumes + all_outphase_volumes + all_inphase_volumes\n",
    "all_masks = all_water_segmentations + all_outphase_segmentations\n",
    "\n",
    "max_z = max(vol.shape[0] for vol in all_vols)\n",
    "max_y = max(vol.shape[1] for vol in all_vols)\n",
    "max_x = max(vol.shape[2] for vol in all_vols)\n",
    "\n",
    "target_shape = (max_z, max_y, max_x)\n",
    "\n",
    "def pad_to_shape(volume, target_shape):\n",
    "    z_pad = target_shape[0] - volume.shape[0]\n",
    "    y_pad = target_shape[1] - volume.shape[1]\n",
    "    x_pad = target_shape[2] - volume.shape[2]\n",
    "\n",
    "    # If volume is already bigger, clip instead of pad\n",
    "    if z_pad < 0 or y_pad < 0 or x_pad < 0:\n",
    "        raise ValueError(f\"Volume shape {volume.shape} larger than target {target_shape}\")\n",
    "\n",
    "    z_before, z_after = z_pad // 2, z_pad - z_pad // 2\n",
    "    y_before, y_after = y_pad // 2, y_pad - y_pad // 2\n",
    "    x_before, x_after = x_pad // 2, x_pad - x_pad // 2\n",
    "\n",
    "    padding = ((z_before, z_after), (y_before, y_after), (x_before, x_after))\n",
    "    return np.pad(volume, padding, mode='constant', constant_values=0)\n",
    "\n",
    "# Apply to all volumes and masks\n",
    "all_water_volumes      = [pad_to_shape(vol, target_shape) for vol in all_water_volumes]\n",
    "all_outphase_volumes   = [pad_to_shape(vol, target_shape) for vol in all_outphase_volumes]\n",
    "all_inphase_volumes    = [pad_to_shape(vol, target_shape) for vol in all_inphase_volumes]\n",
    "all_water_segmentations = [pad_to_shape(vol, target_shape) for vol in all_water_segmentations]\n",
    "all_outphase_segmentations = [pad_to_shape(vol, target_shape) for vol in all_outphase_segmentations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a9a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_water_volumes))\n",
    "print(all_water_volumes[0].shape)\n",
    "print(all_water_segmentations[0].shape)\n",
    "print(all_outphase_volumes[0].shape)\n",
    "print(all_outphase_segmentations[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b7da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import rotate, shift, affine_transform\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Compute center of mass (2D or slice-wise 3D)\n",
    "# -----------------------------------------------------------\n",
    "def compute_com(mask):\n",
    "    indices = np.argwhere(mask > 0)\n",
    "    if len(indices) == 0:\n",
    "        return np.array(mask.shape) / 2  # fallback: center of volume\n",
    "    return indices.mean(axis=0)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Apply rigid transform to MRI (3D)\n",
    "# -----------------------------------------------------------\n",
    "def apply_transform(volume, tx, ty, angle_deg):\n",
    "    angle_rad = np.deg2rad(angle_deg)\n",
    "\n",
    "    # Rotation matrix around z-axis (in-plane)\n",
    "    c, s = np.cos(angle_rad), np.sin(angle_rad)\n",
    "    R = np.array([[c, -s, 0],\n",
    "                  [s,  c, 0],\n",
    "                  [0,  0, 1]])\n",
    "\n",
    "    # Affine transform (rotation + translation)\n",
    "    transform_matrix = R\n",
    "    offset = [-tx, -ty, 0]  # sign convention for scipy\n",
    "\n",
    "    transformed = affine_transform(\n",
    "        volume,\n",
    "        matrix=transform_matrix,\n",
    "        offset=offset,\n",
    "        order=1,\n",
    "        mode='constant',\n",
    "        cval=0.0\n",
    "    )\n",
    "    return transformed\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Apply transform to mask (nearest-neighbor)\n",
    "# -----------------------------------------------------------\n",
    "def rigid_transform_mask(mask, tx, ty, angle_deg):\n",
    "    angle_rad = np.deg2rad(angle_deg)\n",
    "\n",
    "    c, s = np.cos(angle_rad), np.sin(angle_rad)\n",
    "    R = np.array([[c, -s, 0],\n",
    "                  [s,  c, 0],\n",
    "                  [0,  0, 1]])\n",
    "\n",
    "    offset = [-tx, -ty, 0]\n",
    "\n",
    "    transformed = affine_transform(\n",
    "        mask,\n",
    "        matrix=R,\n",
    "        offset=offset,\n",
    "        order=0,       # nearest-neighbor = keeps 0/1 mask\n",
    "        mode='constant',\n",
    "        cval=0\n",
    "    )\n",
    "    return transformed\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 4. IoU calculation\n",
    "# -----------------------------------------------------------\n",
    "def compute_iou(mask1, mask2):\n",
    "    intersection = np.logical_and(mask1 > 0, mask2 > 0).sum()\n",
    "    union       = np.logical_or(mask1 > 0, mask2 > 0).sum()\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    return intersection / union\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 5. Grid-search for best (tx, ty, rotation)\n",
    "# -----------------------------------------------------------\n",
    "def find_best_iou_transform(fixed_mask, moving_mask,\n",
    "                            tx_range=(-10, 10, 3),\n",
    "                            ty_range=(-10, 10, 3),\n",
    "                            angle_range=(-5, 5, 2)):\n",
    "\n",
    "    best_iou = -1\n",
    "    best_params = (0, 0, 0)\n",
    "\n",
    "    tx_vals = np.arange(*tx_range)\n",
    "    ty_vals = np.arange(*ty_range)\n",
    "    ang_vals = np.arange(*angle_range)\n",
    "\n",
    "    for tx in tx_vals:\n",
    "        for ty in ty_vals:\n",
    "            for ang in ang_vals:\n",
    "                moved = rigid_transform_mask(moving_mask, tx, ty, ang)\n",
    "                iou = compute_iou(fixed_mask, moved)\n",
    "\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_params = (tx, ty, ang)\n",
    "\n",
    "    return best_params, best_iou\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 6. MAIN FUNCTION: IOU-BASED RIGID REGISTRATION\n",
    "# -----------------------------------------------------------\n",
    "def rigid_registration_iou(water_mask, out_mask, water_mri, out_mri, in_mri):\n",
    "    print(\"üîß Step 1: Center-of-mass prealignment\")\n",
    "\n",
    "    # --- Center-of-mass alignment (translation only) ---\n",
    "    com_fixed = compute_com(water_mask)\n",
    "    com_moving = compute_com(out_mask)\n",
    "    shift_vector = com_fixed - com_moving\n",
    "\n",
    "    out_mask_pre = shift(out_mask, shift_vector, order=0)\n",
    "    out_mri_pre = shift(out_mri, shift_vector, order=1)\n",
    "    in_mri_pre  = shift(in_mri,  shift_vector, order=1)\n",
    "\n",
    "    print(f\"   applied CoM translation: {shift_vector}\")\n",
    "\n",
    "    print(\"üîß Step 2: Grid-search IoU refinement\")\n",
    "\n",
    "    # --- Optimize small rigid transforms ---\n",
    "    (tx, ty, angle), best_iou = find_best_iou_transform(\n",
    "        water_mask,\n",
    "        out_mask_pre,\n",
    "        tx_range=(-6, 7, 2),   # translations in pixels\n",
    "        ty_range=(-6, 7, 2),\n",
    "        angle_range=(-6, 7, 2) # degrees\n",
    "    )\n",
    "\n",
    "    print(f\"   best IoU = {best_iou:.4f}\")\n",
    "    print(f\"   best transform = tx={tx}, ty={ty}, angle={angle}\")\n",
    "\n",
    "    # --- Apply final transform to MRI volumes ---\n",
    "    registered_out = apply_transform(out_mri_pre, tx, ty, angle)\n",
    "    registered_in  = apply_transform(in_mri_pre,  tx, ty, angle)\n",
    "    registered_mask = rigid_transform_mask(out_mask_pre, tx, ty, angle)\n",
    "\n",
    "    return registered_out, registered_in, registered_mask, (shift_vector, tx, ty, angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5e94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = glob.glob(os.path.join('D:/GEA21/water/A21_01/', \"*\"))[0] + \"/\"\n",
    "_, water_spacing = load_dicom_volume(sample_dir)\n",
    "print(\"Water spacing:\", water_spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aef6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_inphase_images = []\n",
    "registered_outphase_images = []\n",
    "registered_masks = []\n",
    "\n",
    "for i in range(len(all_water_volumes)):\n",
    "    registered_outphase, registered_inphase, registered_mask, params = rigid_registration_iou(\n",
    "        all_water_segmentations[i],\n",
    "        all_outphase_segmentations[i],\n",
    "        all_water_volumes[i],\n",
    "        all_outphase_volumes[i],\n",
    "        all_inphase_volumes[i]\n",
    "    )    \n",
    "    print(\"Registration Done\")\n",
    "    registered_inphase_images.append(registered_inphase)\n",
    "    registered_outphase_images.append(registered_outphase)\n",
    "    registered_masks.append(registered_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(registered_inphase_images[0].shape)\n",
    "print(registered_outphase_images[0].shape)\n",
    "print(registered_masks[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8c67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(50, 60):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.subplot(131)\n",
    "#     plt.imshow(registered_inphase_images[0][i,:,:], cmap='gray')\n",
    "#     plt.subplot(132)\n",
    "#     plt.imshow(registered_outphase_images[0][i,:,:], cmap='gray')\n",
    "#     plt.subplot(133)\n",
    "#     plt.imshow(registered_masks[0][i,:,:], cmap='gray')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1330743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(registered_inphase_images[0].shape)\n",
    "print(registered_outphase_images[0].shape)\n",
    "print(registered_masks[0].shape)\n",
    "print(len(registered_inphase_images))\n",
    "\n",
    "del all_water_volumes, all_inphase_volumes, all_outphase_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a12a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_volumes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c4c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_directory = 'D:/GEA21/fat/'\n",
    "pdff_images = sorted(os.listdir(pdff_directory))\n",
    "\n",
    "for i, image in enumerate(pdff_images):\n",
    "    img_directory = glob.glob(os.path.join(pdff_directory + pdff_images[i], \"*\"))[0] + \"/\"\n",
    "    pdff_volume, _ = load_dicom_volume(img_directory)\n",
    "    pdff_volume = normalize(pdff_volume)\n",
    "    pdff_volumes.append(pad_z(pdff_volume, 104))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b93c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_directory = 'D:/SBIR_PDFF/fat/'\n",
    "pdff_images = sorted(os.listdir(pdff_directory))\n",
    "\n",
    "for i, image in enumerate(pdff_images):\n",
    "    img_directory = glob.glob(os.path.join(pdff_directory + pdff_images[i], \"*\"))[0] + \"/\"\n",
    "    pdff_volume, _ = load_dicom_volume(img_directory)\n",
    "    pdff_volume = normalize(pdff_volume)\n",
    "    pdff_volumes.append(pad_z(pdff_volume, 104))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_directory = 'D:/SBIR_T1/fat/'\n",
    "pdff_images = sorted(os.listdir(pdff_directory))\n",
    "\n",
    "for i, image in enumerate(pdff_images):\n",
    "    img_directory = glob.glob(os.path.join(pdff_directory + pdff_images[i], \"*\"))[0] + \"/\"\n",
    "    pdff_volume, _ = load_dicom_volume(img_directory)\n",
    "    pdff_volume = normalize(pdff_volume)\n",
    "    pdff_volumes.append(pad_z(pdff_volume, 104))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_directory = 'D:/WLS02_UCSD/fat/'\n",
    "pdff_images = sorted(os.listdir(pdff_directory))\n",
    "\n",
    "for i, image in enumerate(pdff_images):\n",
    "    img_directory = glob.glob(os.path.join(pdff_directory + pdff_images[i], \"*\"))[0] + \"/\"\n",
    "    pdff_volume, _ = load_dicom_volume(img_directory)\n",
    "    pdff_volume = normalize(pdff_volume)\n",
    "    pdff_volumes.append(pad_z(pdff_volume, 104))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f121249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pdff_volumes))\n",
    "print(len(registered_inphase_images))\n",
    "print(pdff_volumes[0].shape)\n",
    "print(registered_inphase_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_inphase_dataset = []\n",
    "sliced_outphase_dataset = []\n",
    "sliced_pdff_dataset = []\n",
    "sliced_mask_dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe600d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(img, crop_size=256):\n",
    "    h, w = img.shape[:2]\n",
    "    ch, cw = crop_size, crop_size\n",
    "\n",
    "    # Compute the crop coordinates\n",
    "    start_y = (h - ch) // 2\n",
    "    start_x = (w - cw) // 2\n",
    "    end_y = start_y + ch\n",
    "    end_x = start_x + cw\n",
    "\n",
    "    return img[start_y:end_y, start_x:end_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e4eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdff_volumes)):\n",
    "    for j in range(pdff_volumes[i].shape[0]):\n",
    "\n",
    "        in_slice  = registered_inphase_images[i][j, :, :]\n",
    "        out_slice = registered_outphase_images[i][j, :, :]\n",
    "        pdff_slice = pdff_volumes[i][j, :, :]\n",
    "\n",
    "        in_cropped  = center_crop(in_slice, 256)\n",
    "        out_cropped = center_crop(out_slice, 256)\n",
    "\n",
    "        sliced_inphase_dataset.append(in_cropped)\n",
    "        sliced_outphase_dataset.append(out_cropped)\n",
    "        sliced_pdff_dataset.append(pdff_volumes[i][j,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5658d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sliced_inphase_dataset)/104)\n",
    "print(len(sliced_pdff_dataset)/104)\n",
    "print(sliced_inphase_dataset[0].shape)\n",
    "print(sliced_pdff_dataset[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e547ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del registered_inphase_images, registered_outphase_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = []\n",
    "\n",
    "for in_slice, out_slice in zip(sliced_inphase_dataset, sliced_outphase_dataset):\n",
    "    stacked = np.stack([in_slice, out_slice], axis=-1)  # shape: (H, W, 2)\n",
    "    input_dataset.append(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_dataset[0].shape)\n",
    "print(len(input_dataset)/104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f69725",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dataset = np.array(input_dataset)\n",
    "sliced_pdff_dataset = np.array(sliced_pdff_dataset)\n",
    "sliced_pdff_dataset = np.expand_dims(sliced_pdff_dataset, axis=3)\n",
    "\n",
    "print(\"sliced image dataset: \", len(sliced_inphase_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7213165",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_pdff_dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe4c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sliced_inphase_dataset, sliced_outphase_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f11e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = []\n",
    "new_pdff = []\n",
    "\n",
    "for img, pdf in zip(input_dataset, sliced_pdff_dataset):\n",
    "    if not (\n",
    "        np.all(img[:,:,0] == 0) or\n",
    "        np.all(img[:,:,1] == 0) or\n",
    "        np.all(pdf == 0)\n",
    "    ):\n",
    "        new_input.append(img)\n",
    "        new_pdff.append(pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = np.array(new_input)\n",
    "new_pdff = np.array(new_pdff)\n",
    "new_pdff = np.expand_dims(new_pdff, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c1f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(55, 60):\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.subplot(131)\n",
    "#     plt.imshow(input_dataset[i][:,:,0], cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(132)\n",
    "#     plt.imshow(input_dataset[i][:,:,1], cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     plt.subplot(133)\n",
    "#     plt.imshow(sliced_pdff_dataset[i], cmap='gray')\n",
    "#     plt.axis('off')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f952454",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cae3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import random\n",
    "import nibabel\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.ndimage import rotate\n",
    "from nibabel import load\n",
    "from IPython.display import Image, display\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr_metric(y_true, y_pred):\n",
    "    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
    "\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    return tf.image.ssim(y_true, y_pred, max_val=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "    ssim = tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    return 0.5 * mae + 0.5 * (1 - ssim)\n",
    "\n",
    "def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    # Contracting path\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    c1 = BatchNormalization()(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    c2 = BatchNormalization()(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    c3 = BatchNormalization()(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    c4 = BatchNormalization()(c4)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    c5 = BatchNormalization()(c5)\n",
    "\n",
    "    # Expansive path\n",
    "    u6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "    c6 = BatchNormalization()(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "    c7 = BatchNormalization()(c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "    c8 = BatchNormalization()(c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "    c9 = BatchNormalization()(c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss=combined_loss, metrics=[psnr_metric, ssim_metric])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec8dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH  = 256\n",
    "IMG_CHANNELS = 2\n",
    "\n",
    "def get_model():\n",
    "    return simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_input, new_pdff, test_size=0.2)\n",
    "\n",
    "f = open(f\"C:/Users/User/Desktop/inout_pdff/outputs/output.txt\", \"a\")\n",
    "print(\"FOLD----------------------------------\", file=f)\n",
    "print(\"x-training: \", len(X_train), file=f)\n",
    "print(\"x-testing: \", len(X_test), file=f)\n",
    "print(\"y-training: \", len(y_train), file=f)\n",
    "print(\"y-testing: \", len(y_test), file=f)\n",
    "f.close()\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "checkpoint = ModelCheckpoint(f'C:/Users/User/Desktop/inout_pdff/outputs/model.h5', monitor='val_loss', save_best_only=True)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                factor=0.5, \n",
    "                                patience=10, \n",
    "                                verbose=1, \n",
    "                                min_lr=1e-6)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    epochs=500,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    shuffle=False,\n",
    "                    callbacks = [checkpoint, early_stopping, lr_reduction])\n",
    "\n",
    "f = open(f'C:/Users/User/Desktop/inout_pdff/outputs/output.txt', \"a\")\n",
    "print(\"Stopped at epoch:\", early_stopping.stopped_epoch)\n",
    "f.close()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(history.history['loss'], color='r')\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val.'], loc='upper right')\n",
    "plt.savefig(f'C:/Users/User/Desktop/inout_pdff/outputs/process.png')\n",
    "plt.close()\n",
    "\n",
    "min_loss = min(history.history['loss'])\n",
    "min_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "\n",
    "f = open(f'C:/Users/User/Desktop/inout_pdff/outputs/output.txt', \"a\")\n",
    "print(\"FOLD------------------------------------------\", file=f)\n",
    "print(\"Min Loss: \", min_loss, file=f)\n",
    "print(\"Min Val Loss: \", min_val_loss, file=f)\n",
    "f.close()\n",
    "\n",
    "model.load_weights(f'C:/Users/User/Desktop/inout_pdff/outputs/model.h5')\n",
    "\n",
    "for z in range(25):\n",
    "    test_img_number = random.randint(0, len(X_test)-1)\n",
    "    test_img = X_test[z]\n",
    "    ground_truth = y_test[z]\n",
    "    test_img_input = np.expand_dims(test_img, axis=0)\n",
    "    prediction = model.predict(test_img_input)[0, :, :, 0]\n",
    "\n",
    "    original_image_normalized = ground_truth.astype(float) / np.max(ground_truth)\n",
    "    colored_mask = plt.get_cmap('jet')(prediction / np.max(prediction))\n",
    "    alpha = 0.5 \n",
    "    colored_mask[..., 3] = np.where(prediction > 0, alpha, 0)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(141)\n",
    "    plt.title('Inphase Image')\n",
    "    plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "    plt.subplot(142)\n",
    "    plt.title('Outphase Image')\n",
    "    plt.imshow(test_img[:,:,1], cmap='gray')\n",
    "    plt.subplot(143)\n",
    "    plt.title('PDFF (Ground Truth)')\n",
    "    plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "    plt.subplot(144)\n",
    "    plt.title('Prediction')\n",
    "    plt.imshow(prediction, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.savefig(f'C:/Users/User/Desktop/inout_pdff/outputs/predictions/{z}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb73d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(25):\n",
    "    test_img_number = random.randint(0, len(X_test)-1)\n",
    "    test_img = X_test[z]\n",
    "    ground_truth = y_test[z]\n",
    "    test_img_input = np.expand_dims(test_img, axis=0)\n",
    "    prediction = model.predict(test_img_input)[0, :, :, 0]\n",
    "\n",
    "    original_image_normalized = ground_truth.astype(float) / np.max(ground_truth)\n",
    "    colored_mask = plt.get_cmap('jet')(prediction / np.max(prediction))\n",
    "    alpha = 0.5 \n",
    "    colored_mask[..., 3] = np.where(prediction > 0, alpha, 0)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(141)\n",
    "    plt.title('Inphase Image')\n",
    "    plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "    plt.subplot(142)\n",
    "    plt.title('Outphase Image')\n",
    "    plt.imshow(test_img[:,:,1], cmap='gray')\n",
    "    plt.subplot(143)\n",
    "    plt.title('PDFF (Ground Truth)')\n",
    "    plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "    plt.subplot(144)\n",
    "    plt.title('Prediction')\n",
    "    plt.imshow(prediction, cmap='gray')\n",
    "    plt.show()\n",
    "    plt.savefig(f'C:/Users/User/Desktop/inout_pdff/outputs/predictions/{z}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c92158a",
   "metadata": {},
   "source": [
    "### Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_unet_model(256, 256, 2)\n",
    "model.load_weights(f'C:/Users/User/Desktop/inout_pdff/outputs0/model.h5')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for z in range(len(input_dataset)):\n",
    "        test_img = input_dataset[z]\n",
    "        test_img_input = np.expand_dims(test_img, axis=0)\n",
    "        prediction = model.predict(test_img_input)[0, :, :, 0]\n",
    "        predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c76954",
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(5):\n",
    "    test_img_number = random.randint(0, len(predictions)-1)\n",
    "    test_img = input_dataset[test_img_number]\n",
    "    ground_truth = sliced_pdff_dataset[test_img_number]\n",
    "    prediction = predictions[test_img_number]\n",
    "    original_image_normalized = ground_truth.astype(float) / np.max(ground_truth)\n",
    "    colored_mask = plt.get_cmap('jet')(prediction / np.max(prediction))\n",
    "    alpha = 0.5 \n",
    "    colored_mask[..., 3] = np.where(prediction > 0, alpha, 0)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.subplot(141)\n",
    "    plt.title('Inphase Image')\n",
    "    plt.imshow(test_img[:,:,0], cmap='gray')\n",
    "    plt.subplot(142)\n",
    "    plt.title('Outphase Image')\n",
    "    plt.imshow(test_img[:,:,1], cmap='gray')\n",
    "    plt.subplot(143)\n",
    "    plt.title('PDFF (Ground Truth)')\n",
    "    plt.imshow(ground_truth[:,:,0], cmap='gray')\n",
    "    plt.subplot(144)\n",
    "    plt.title('Prediction')\n",
    "    plt.imshow(prediction, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b67c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_volumes = np.array(predictions).shape[0] // 104\n",
    "\n",
    "prediction_volumes = np.array([predictions[i*104:(i+1)*104]  for i in range(num_volumes)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe55b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_middle_slices = []\n",
    "\n",
    "for volume in prediction_volumes:\n",
    "    middle_slice = []\n",
    "    middle_slice.append(volume[51])\n",
    "    middle_slice.append(volume[52])\n",
    "    middle_slice.append(volume[53])\n",
    "    pred_middle_slices.append(middle_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b78687",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_middle_slices = []\n",
    "\n",
    "for volume in pdff_volumes:\n",
    "    middle_slice = []\n",
    "    middle_slice.append(volume[51])\n",
    "    middle_slice.append(volume[52])\n",
    "    middle_slice.append(volume[53])\n",
    "    pdff_middle_slices.append(middle_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred_middle_slices))\n",
    "print(len(pdff_middle_slices))\n",
    "np.array(pdff_middle_slices[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(pred_middle_slices)):\n",
    "    center = (70, 140)  # (x, y) format\n",
    "    radius = 5         # radius of the circle\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "    for j in range(3):\n",
    "        # Convert slice to uint8 image if necessary\n",
    "        img = pred_middle_slices[i][j]\n",
    "        pdff = pdff_middle_slices[i][j]\n",
    "        \n",
    "\n",
    "        # Normalize if it's float or not in [0, 255]\n",
    "        if img.dtype != np.uint8:\n",
    "            img = (img - img.min()) / (img.max() - img.min()) * 255\n",
    "            img = img.astype(np.uint8)\n",
    "\n",
    "        if pdff.dtype != np.uint8:\n",
    "            pdff = (pdff - pdff.min()) / (pdff.max() - pdff.min()) * 255\n",
    "            pdff = pdff.astype(np.uint8)\n",
    "\n",
    "        # Convert to BGR to draw colored circle (if needed), or stay in grayscale\n",
    "        img_color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        pdff_color = cv2.cvtColor(pdff, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "        # Draw the circle on the image\n",
    "        cv2.circle(img_color, center, radius, (0, 0, 255), thickness=1)  # Red circle (BGR)\n",
    "        cv2.circle(pdff_color, center, radius, (0, 0, 255), thickness=1)\n",
    "\n",
    "        # Display\n",
    "        axs[0][j].imshow(cv2.cvtColor(img_color, cv2.COLOR_BGR2RGB))  # Convert to RGB for matplotlib\n",
    "        axs[0][j].set_title(f\"Slice {j} with Circle\")\n",
    "        axs[0][j].axis('on')\n",
    "\n",
    "        axs[1][j].imshow(cv2.cvtColor(pdff_color, cv2.COLOR_BGR2RGB))  # Convert to RGB for matplotlib\n",
    "        axs[1][j].set_title(f\"Slice {j} with Circle\")\n",
    "        axs[1][j].axis('on')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_values = []\n",
    "prediction_values = []\n",
    "\n",
    "center = (70, 140)  # (x, y) format\n",
    "radius = 5         # radius of the circle\n",
    "\n",
    "circle_mask = np.zeros((256, 256), dtype=np.uint8)\n",
    "cv2.circle(circle_mask, center, radius, 1, thickness=-1)\n",
    "\n",
    "for i in range(len(pdff_middle_slices)):\n",
    "    pdff_stats = []\n",
    "    prediction_stats = []\n",
    "    for j in range(3):\n",
    "        pdff_stats.append((pdff_middle_slices[i][j] * circle_mask))\n",
    "        prediction_stats.append(((pred_middle_slices[i][j]) * circle_mask))\n",
    "    pdff_values.append(pdff_stats)\n",
    "    prediction_values.append(prediction_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19efb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_stats = []\n",
    "prediction_stats = []\n",
    "\n",
    "for i in range(len(pdff_values)):\n",
    "    combined_pdff =  np.concatenate(pdff_values[i])\n",
    "    non_zero_pdff = combined_pdff[combined_pdff != 0]\n",
    "    mean_non_zero_pdff = np.mean(non_zero_pdff)\n",
    "    std_non_zero_pdff = np.std(non_zero_pdff)\n",
    "\n",
    "    combined_pred = np.concatenate(prediction_values[i])\n",
    "    non_zero_pred = combined_pred[combined_pred != 0]\n",
    "    mean_non_zero_pred = np.mean(non_zero_pred)\n",
    "    std_non_zero_pred = np.std(non_zero_pred)\n",
    "\n",
    "    pdff_stats.append([mean_non_zero_pdff, std_non_zero_pdff])\n",
    "    prediction_stats.append([mean_non_zero_pred, std_non_zero_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a85e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = []\n",
    "\n",
    "for i in range(len(pdff_stats)):\n",
    "    difference = pdff_stats[i][0] - prediction_stats[i][0]\n",
    "    differences.append(difference)\n",
    "\n",
    "np.mean(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cbe637",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdff_stats = np.array(pdff_stats)\n",
    "prediction_stats = np.array(prediction_stats)\n",
    "\n",
    "pdff_mean_values = pdff_stats[:, 0]  \n",
    "pdff_std_values = pdff_stats[:, 1] \n",
    "pred_mean_values = prediction_stats[:, 0] \n",
    "pred_std_values = prediction_stats[:, 1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75651266",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'PDFF Mean': pdff_mean_values,\n",
    "    'PDFF STD': pdff_std_values,\n",
    "    'Prediction Mean': pred_mean_values,\n",
    "    'Prediction STD': pred_std_values,\n",
    "    'Difference (PDFF- Prediction)': differences\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615b25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"iop_output.xlsx\", index=False, sheet_name=\"Stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13494f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
